{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenador de Gatos y Perros\n",
    "Alan Badillo Salas (badillo.soft@hotmail.com)\n",
    "\n",
    "Este mini-proyecto tiene la intención de crear una red neuronal de tipo CNN, para aprender a determinar si una imagen corresponde a un gato o a un perro.\n",
    "\n",
    "Para más información sobre las redes CNN visita: https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es descargar el archivo zip que contiene 10,000 imágenes de gatos y perros en una resolución de 32x32 pixeles a color. Cada imagen tiene como nombre su identificador. El archivo de imágenes lo puede descargar de http://badillosoft.com/train_cat_dog.zip.\n",
    "\n",
    "Una vez descargado el archivo debemos descomprimirlo y todas las imágenes se encontrarán la carpeta `train_cat_dog`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han importado las librerías necesarias para el análisis\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, BatchNormalization\n",
    "from keras import optimizers, regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Se han importado las librerías necesarias para el análisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que cargar el `DataFrame` con los id's de las imágenes y sus etiquetas para utilizarlos en el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    10000 non-null int64\n",
      "id            10000 non-null int64\n",
      "label         10000 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 234.4+ KB\n",
      "None\n",
      "   Unnamed: 0  id label\n",
      "0           9  10   cat\n",
      "1          17  18   cat\n",
      "2          21  22   cat\n",
      "3          26  27   cat\n",
      "4          27  28   dog\n"
     ]
    }
   ],
   "source": [
    "train_cat_dog = pd.read_csv(\"http://badillosoft.com/train_cat_dog.csv\")\n",
    "\n",
    "print(train_cat_dog.info())\n",
    "print(train_cat_dog.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un generador de datos para que tome el `DataFrame` de pandas que contiene los id's de las imágenes y sus etiquetas (`train_cat_dog`). Observa que el generador de datos define que el 20% de ellos serán utilizados para la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.ImageDataGenerator object at 0x11ae22150>\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "\n",
    "print(datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el generador de entrenamiento, esto se refiere a un generador que va a cargar las imágenes desde nuestra carpeta basado en el `DataFrame` (`train_cat_dog`) para proveer el `x_train` y el `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"training\",                 # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar vamos a crear un generador de imágenes para las validaciones, esto creará los `x_test` y los `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"validation\",               # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los generadores anteriores, ya podemos alimentar nuestra red CNN. Por lo que, primero debemos crear la CNN como sigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 27,586\n",
      "Trainable params: 27,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Capas Convolutivas (El filtro/kernel)\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32, 32, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "# Capas Pooling (El reductor)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Capa Dropout (La pérdida)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Capa Flatten (El aplanador)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Capas de Clasificación (El aprendizaje)\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos el modelo, podemos entrenarlo con los generadores `train_generator` y `test_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.6778 - acc: 0.5745 - val_loss: 0.6341 - val_acc: 0.6588\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 24s 97ms/step - loss: 0.6257 - acc: 0.6520 - val_loss: 0.5960 - val_acc: 0.6855\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 23s 93ms/step - loss: 0.5938 - acc: 0.6860 - val_loss: 0.5781 - val_acc: 0.7048\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 23s 94ms/step - loss: 0.5700 - acc: 0.7022 - val_loss: 0.5552 - val_acc: 0.7236\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.5546 - acc: 0.7147 - val_loss: 0.5524 - val_acc: 0.7221\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 20s 82ms/step - loss: 0.5383 - acc: 0.7300 - val_loss: 0.5696 - val_acc: 0.6966\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.5219 - acc: 0.7438 - val_loss: 0.5231 - val_acc: 0.7439\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 23s 90ms/step - loss: 0.5149 - acc: 0.7480 - val_loss: 0.5365 - val_acc: 0.7332\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.5022 - acc: 0.7548 - val_loss: 0.5346 - val_acc: 0.7292\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 19s 77ms/step - loss: 0.4941 - acc: 0.7631 - val_loss: 0.5125 - val_acc: 0.7546\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x103bcef50>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos los tamaños de salto para los kernels\n",
    "STEP_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_TEST = test_generator.n // test_generator.batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,      # Indica quién genera las imágenes de entranamiento\n",
    "    steps_per_epoch=STEP_TRAIN,     # Indica cuántos pasos se realizarán por época\n",
    "    validation_data=test_generator, # Indica el generador de imágenes para la validación\n",
    "    validation_steps=STEP_TEST,     # Indica cuántos pasos se realizarán para la validación\n",
    "    epochs=10                       # Indica las épocas de entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la red CNN ya está entrenada, por lo que medimos su desempeño con las imágenes de validación (`test_generator`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49700924293781684, 0.7627032520325203]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate_generator(generator=test_generator, steps=STEP_TEST)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el clasificador con imágenes reales\n",
    "\n",
    "Hasta aquí ya hemos entrenado nuestro modelo para aprender a reconocer imágenes de gatos y perros, por lo que podemos ahora descargar una imagen desde internet, reducirla a una resolución de `32x32` pixeles y evaluarla en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=750x563 at 0x11C1BBD90>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "# Python 2\n",
    "from StringIO import StringIO\n",
    "\n",
    "# Gato\n",
    "#url = \"https://www.readersdigest.ca/wp-content/uploads/sites/14/2011/01/4-ways-cheer-up-depressed-cat.jpg\"\n",
    "# Perro\n",
    "#url = \"https://img.huffingtonpost.com/asset/5b7fdeab1900001d035028dc.jpeg?cache=sixpwrbb1s&ops=1910_1000\"\n",
    "# Gato\n",
    "url = \"https://amp.businessinsider.com/images/5654150584307663008b4ed8-750-563.jpg\"\n",
    "# Perro\n",
    "#url = \"https://www.guidedogs.org/wp-content/uploads/2018/01/Mobile.jpg\"\n",
    "\n",
    "# Python 2\n",
    "response = requests.get(url)\n",
    "# Python 3\n",
    "# response = request.get(url, stream=True)\n",
    "\n",
    "# Python 2\n",
    "im = Image.open(StringIO(response.content))\n",
    "# Python 3\n",
    "# im = Image.open(response.raw)\n",
    "\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hay que reducir la imagen a `32x32` pixeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x11C07DBD0>\n"
     ]
    }
   ],
   "source": [
    "im = im.resize((32, 32), Image.NEAREST)\n",
    "\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos convertir la imagen en un arreglo de números `(32, 32, 3)` y convertirlo a una matriz para que se pueda hacer la predicción. Recordemos que `model.predict` espera una matriz de muestras para hacer la predicción en todas las muestras (no podemos manderle sólo un ejemplo para la predicción)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[202 188 175]\n",
      "   [198 188 176]\n",
      "   [199 187 175]\n",
      "   ...\n",
      "   [202 170 121]\n",
      "   [136 106  68]\n",
      "   [ 37  35  23]]\n",
      "\n",
      "  [[198 184 171]\n",
      "   [198 184 173]\n",
      "   [195 183 171]\n",
      "   ...\n",
      "   [204 170 124]\n",
      "   [143 113  75]\n",
      "   [ 29  26  17]]\n",
      "\n",
      "  [[197 183 170]\n",
      "   [195 181 168]\n",
      "   [193 181 167]\n",
      "   ...\n",
      "   [205 170 128]\n",
      "   [150 117  86]\n",
      "   [ 24  21  14]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 62  45  29]\n",
      "   [ 54  38  15]\n",
      "   [ 53  40  21]\n",
      "   ...\n",
      "   [189 157 134]\n",
      "   [208 176 165]\n",
      "   [204 171 162]]\n",
      "\n",
      "  [[ 51  35  19]\n",
      "   [ 54  39  18]\n",
      "   [116  87  53]\n",
      "   ...\n",
      "   [153 119  91]\n",
      "   [199 166 157]\n",
      "   [203 169 160]]\n",
      "\n",
      "  [[ 40  32  13]\n",
      "   [ 77  60  34]\n",
      "   [189 155 117]\n",
      "   ...\n",
      "   [115  84  56]\n",
      "   [201 173 161]\n",
      "   [218 188 178]]]]\n"
     ]
    }
   ],
   "source": [
    "im_array = np.asarray(im)\n",
    "\n",
    "x_test = np.array([im_array]) # np.array([im1, im2, im3, ...])\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos hacer la predicción sobre `x_test`. El resultado nos va a indicar un vector con la probabilidad de que pertenezca a las distintas clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test)\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos dos clases y nos está indicando que tiene una probabilidad `0` de pertenecer a la primer clase y una probabilidad de `1` de pertenecer a la segunda clase. Para ver las clases hacemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'cat': 0}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a tomar las clases y los resultados de la predicción para que imprima que combine los scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog: 0.0\n",
      "cat: 1.0\n"
     ]
    }
   ],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "for label in class_indices:\n",
    "    for score in predict:\n",
    "        index = class_indices[label]\n",
    "        print(\"{}: {}\".format(label, score[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el modelo y entrenamiento\n",
    "\n",
    "Ahora que ya todo está listo podemos guardar el modelo y su entrenamiento para poder utilizarlo en otras aplicaciones como se verá más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"cat_dog_classes.json\", \"w\") as f:\n",
    "    f.write(json.dumps(class_indices))\n",
    "\n",
    "with open(\"cat_dog_model.json\", \"w\") as f:\n",
    "    f.write(model.to_json())\n",
    "\n",
    "model.save(\"cat_dog_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponer una interfaz web y servicios web (API-REST)\n",
    "\n",
    "Finalmente podemos generar mediante flask un servidor que reciba la url de una imagen y nos diga si es perro o si es gato. Así como proveer una página web con una caja y botón que nos diga sobre una url si es gato o si es perro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [01/Dec/2018 13:38:16] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [01/Dec/2018 13:38:16] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [01/Dec/2018 13:38:21] \"\u001b[37mGET /api/cat_dog?url=https%3A%2F%2Famp.businessinsider.com%2Fimages%2F5654150584307663008b4ed8-750-563.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [01/Dec/2018 13:38:21] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [01/Dec/2018 13:38:45] \"\u001b[37mGET /api/cat_dog?url=https%3A%2F%2Fencrypted-tbn0.gstatic.com%2Fimages%3Fq%3Dtbn%3AANd9GcRWB6W7GLsVLLDYp72NtIGnB4r1aJVpVnOed17IB2abKLY_8tAl HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [01/Dec/2018 13:38:45] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [01/Dec/2018 13:39:09] \"\u001b[37mGET /api/cat_dog?url=https%3A%2F%2Fthenypost.files.wordpress.com%2F2018%2F05%2F180516-woman-mauled-by-angry-wiener-dogs-feature.jpg%3Fquality%3D90%26strip%3Dall%26w%3D618%26h%3D410%26crop%3D1 HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [01/Dec/2018 13:39:09] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "# Python 2\n",
    "from StringIO import StringIO\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "with open(\"cat_dog_model.json\") as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "model.load_weights(\"cat_dog_weights.h5\")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "with open(\"cat_dog_classes.json\") as f:\n",
    "    class_indices = json.load(f)\n",
    "\n",
    "def cat_dog_predict(url):\n",
    "    response = requests.get(url)\n",
    "    im = Image.open(StringIO(response.content))\n",
    "    im = im.resize((32, 32), resample=Image.NEAREST)\n",
    "    im_vec = np.asarray(im)\n",
    "    x_test = np.array([im_vec])\n",
    "    predict = model.predict(x_test)[0]\n",
    "    score = {}\n",
    "    for cat in class_indices:\n",
    "        index = class_indices[cat]\n",
    "        score[cat] = predict[index]\n",
    "    return score\n",
    "\n",
    "#print(cat_dog_predict(\"https://www.guidedogs.org/wp-content/uploads/2018/01/Mobile.jpg\"))\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "html = '''\n",
    "<form action=\"/api/cat_dog\" method=\"get\">\n",
    "    <input id=\"url\" name=\"url\" placeholder=\"url de gato o perro\" >\n",
    "</form>\n",
    "'''\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return html\n",
    "\n",
    "@app.route(\"/api/cat_dog\")\n",
    "def cat_dog():\n",
    "    url = request.args[\"url\"]\n",
    "    score = cat_dog_predict(url)\n",
    "    result = '<img src=\"{}\" width=\"200\" >'.format(url)\n",
    "    for cat in score:\n",
    "        result += \"<h1>{}: {}</h1>\".format(cat, score[cat])\n",
    "    result += html\n",
    "    return result\n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
