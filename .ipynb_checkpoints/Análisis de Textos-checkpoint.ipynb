{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Autobiografía, by Rubén Darío\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r\n",
      "with this eBook or online at www.gutenberg.org/license\r\n",
      "\r\n",
      "\r\n",
      "Title: Autobiografía\r\n",
      "       Obras Completas Vol. XV\r\n",
      "\r\n",
      "Author: Rubén Darío\r\n",
      "\r\n",
      "Release Date: May 11, 2016 [EBook #52050]\r\n",
      "\r\n",
      "Language: Spanish\r\n",
      "\r\n",
      "Character set enc\n"
     ]
    }
   ],
   "source": [
    "corpus = open(\"autobiografia.txt\").read()\n",
    "\n",
    "print(corpus[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del corpus: 265193\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del corpus: {}\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras: 42146\n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'autobiograf\\xc3\\xada', 'by', 'rub\\xc3\\xa9n', 'dar\\xc3\\xado', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'license', 'title', 'autobiograf\\xc3\\xada', 'obras', 'completas', 'vol', 'xv', 'author', 'rub\\xc3\\xa9n', 'dar\\xc3\\xado', 'release', 'date', 'may', 'ebook', 'language', 'spanish', 'character', 'set', 'encoding', 'utf', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'autobiograf\\xc3', 'a', 'produced', 'by', 'josep', 'cols', 'canals', 'chuck', 'greif', 'and', 'the', 'online', 'distributed', 'proofreading', 'team', 'at', 'http', 'www']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "words = []\n",
    "\n",
    "for m in re.finditer(r\"[a-zA-Záéíóúñ]+\", corpus):\n",
    "    word = m.group(0)\n",
    "    words.append(word.lower())\n",
    "    \n",
    "# words = [m.group(0).lower() for m in re.finditer(r\"[\\wáéíóúñ]+\", corpus)]\n",
    "\n",
    "print(\"Palabras: {}\".format(len(words)))\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count(\"Catedral\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freq(word):\n",
    "    return words.count(word.lower())\n",
    "\n",
    "freq(\"Casa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 8845 palabras diferentes\n",
      "['a', 'abacial', 'abajo', 'abandonar', 'abandonar\\xc3\\xada', 'abandon\\xc3\\xa9', 'abandon\\xc3\\xb3', 'abanicos', 'abarcaba', 'abarzuza', 'abate', 'abderram\\xc3\\xa1n', 'abeja', 'abejas', 'abide', 'abierta', 'abierto', 'abogado', 'abominadores', 'abonaban', 'abordaje', 'about', 'abrazos', 'abraz\\xc3\\xb3', 'abriese', 'abrir', 'abrirse', 'abrojos', 'abrumadoras', 'abruzzos', 'abr\\xc3\\xad', 'abr\\xc3\\xada', 'absoluta', 'absolutamente', 'absoluto', 'abuela', 'abuelo', 'abundante', 'abundaron', 'abusaba', 'acaba', 'acababa', 'acababan', 'acabado', 'acabar', 'acabo', 'acab\\xc3', 'acab\\xc3\\xa1semos', 'acab\\xc3\\xb3', 'academia', 'acad\\xc3\\xa9mico', 'acad\\xc3\\xa9micos', 'acanelada', 'acariciaba', 'acariciado', 'acaso', 'accept', 'accepted', 'accepting', 'access', 'accessed', 'accessible', 'acci\\xc3\\xb3n', 'accordance', 'aceite', 'acento', 'acentos', 'acentuaban', 'aceptar', 'aceptar\\xc3\\xa1', 'aceptase', 'acept\\xc3\\xa1bamos', 'acept\\xc3\\xa9', 'acerado', 'acercaba', 'acercamos', 'acercando', 'acercarse', 'acerc\\xc3\\xa1ndose', 'acerc\\xc3\\xb3', 'acetosa', 'acevedo', 'aclam\\xc3\\xb3', 'acogida', 'acogido', 'acogiera', 'acompa\\xc3\\xb1a', 'acompa\\xc3\\xb1aba', 'acompa\\xc3\\xb1ada', 'acompa\\xc3\\xb1ado', 'acompa\\xc3\\xb1ados', 'acompa\\xc3\\xb1amiento', 'acompa\\xc3\\xb1antes', 'acompa\\xc3\\xb1ar', 'acompa\\xc3\\xb1arle', 'acompa\\xc3\\xb1arme', 'acompa\\xc3\\xb1ase', 'acompa\\xc3\\xb1\\xc3\\xa1banle', 'acompa\\xc3\\xb1\\xc3\\xa9', 'aconsej\\xc3\\xb3']\n"
     ]
    }
   ],
   "source": [
    "base_words = sorted(list(set(words)))\n",
    "\n",
    "print(\"Se encontraron {} palabras diferentes\".format(len(base_words)))\n",
    "print(base_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def index(word):\n",
    "    if base_words.count(word.lower()) > 0:\n",
    "        return base_words.index(word.lower()) + 1\n",
    "    return 0\n",
    "\n",
    "index(\"casa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola', 'como', 'has', 'estado']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_words(text):\n",
    "    return [m.group(0).lower() for m in re.finditer(r\"[\\wáéíóúñ]+\", text)]\n",
    "    \n",
    "text_to_words(\"Hola como has estado?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1647, 3926, 3142]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_to_vec(words):\n",
    "    return [index(word) for word in words]\n",
    "\n",
    "words_to_vec(['hola', 'como', 'has', 'estado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1647, 3926, 3142]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 20\n",
    "def norm_vec(vec):\n",
    "    vec = vec[:MAX_LEN]\n",
    "    n = len(vec)\n",
    "    vec = [0] * (MAX_LEN - n) + vec\n",
    "    return vec\n",
    "\n",
    "norm_vec([0, 1647, 3926, 3142])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5125, 4809, 0, 8720, 7950, 5378, 7444]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_vec(text):\n",
    "    words = text_to_words(text)\n",
    "    vec = words_to_vec(words)\n",
    "    vec = norm_vec(vec)\n",
    "    return vec\n",
    "\n",
    "text_to_vec(\"hola me llamo Damian y tengo mucha sed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
