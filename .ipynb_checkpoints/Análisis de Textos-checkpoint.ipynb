{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿The Project Gutenberg EBook of Autobiografía, by Rubén Darío\r\n",
      "\r\n",
      "This eBook is for the use of anyone anywhere at no cost and with\r\n",
      "almost no restrictions whatsoever.  You may copy it, give it away or\r\n",
      "re-use it under the terms of the Project Gutenberg License included\r\n",
      "with this eBook or online at www.gutenberg.org/license\r\n",
      "\r\n",
      "\r\n",
      "Title: Autobiografía\r\n",
      "       Obras Completas Vol. XV\r\n",
      "\r\n",
      "Author: Rubén Darío\r\n",
      "\r\n",
      "Release Date: May 11, 2016 [EBook #52050]\r\n",
      "\r\n",
      "Language: Spanish\r\n",
      "\r\n",
      "Character set enc\n"
     ]
    }
   ],
   "source": [
    "corpus = open(\"autobiografia.txt\").read()\n",
    "\n",
    "print(corpus[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño del corpus: 265193\n"
     ]
    }
   ],
   "source": [
    "print(\"Tamaño del corpus: {}\".format(len(corpus)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras: 42146\n",
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'autobiograf\\xc3\\xada', 'by', 'rub\\xc3\\xa9n', 'dar\\xc3\\xado', 'this', 'ebook', 'is', 'for', 'the', 'use', 'of', 'anyone', 'anywhere', 'at', 'no', 'cost', 'and', 'with', 'almost', 'no', 'restrictions', 'whatsoever', 'you', 'may', 'copy', 'it', 'give', 'it', 'away', 'or', 're', 'use', 'it', 'under', 'the', 'terms', 'of', 'the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'or', 'online', 'at', 'www', 'gutenberg', 'org', 'license', 'title', 'autobiograf\\xc3\\xada', 'obras', 'completas', 'vol', 'xv', 'author', 'rub\\xc3\\xa9n', 'dar\\xc3\\xado', 'release', 'date', 'may', 'ebook', 'language', 'spanish', 'character', 'set', 'encoding', 'utf', 'start', 'of', 'this', 'project', 'gutenberg', 'ebook', 'autobiograf\\xc3', 'a', 'produced', 'by', 'josep', 'cols', 'canals', 'chuck', 'greif', 'and', 'the', 'online', 'distributed', 'proofreading', 'team', 'at', 'http', 'www']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "words = []\n",
    "\n",
    "for m in re.finditer(r\"[a-zA-Záéíóúñ]+\", corpus):\n",
    "    word = m.group(0)\n",
    "    words.append(word.lower())\n",
    "    \n",
    "# words = [m.group(0).lower() for m in re.finditer(r\"[\\wáéíóúñ]+\", corpus)]\n",
    "\n",
    "print(\"Palabras: {}\".format(len(words)))\n",
    "print(words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.count(\"Catedral\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def freq(word):\n",
    "    return words.count(word.lower())\n",
    "\n",
    "freq(\"Casa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se encontraron 8845 palabras diferentes\n",
      "['a', 'abacial', 'abajo', 'abandonar', 'abandonar\\xc3\\xada', 'abandon\\xc3\\xa9', 'abandon\\xc3\\xb3', 'abanicos', 'abarcaba', 'abarzuza', 'abate', 'abderram\\xc3\\xa1n', 'abeja', 'abejas', 'abide', 'abierta', 'abierto', 'abogado', 'abominadores', 'abonaban', 'abordaje', 'about', 'abrazos', 'abraz\\xc3\\xb3', 'abriese', 'abrir', 'abrirse', 'abrojos', 'abrumadoras', 'abruzzos', 'abr\\xc3\\xad', 'abr\\xc3\\xada', 'absoluta', 'absolutamente', 'absoluto', 'abuela', 'abuelo', 'abundante', 'abundaron', 'abusaba', 'acaba', 'acababa', 'acababan', 'acabado', 'acabar', 'acabo', 'acab\\xc3', 'acab\\xc3\\xa1semos', 'acab\\xc3\\xb3', 'academia', 'acad\\xc3\\xa9mico', 'acad\\xc3\\xa9micos', 'acanelada', 'acariciaba', 'acariciado', 'acaso', 'accept', 'accepted', 'accepting', 'access', 'accessed', 'accessible', 'acci\\xc3\\xb3n', 'accordance', 'aceite', 'acento', 'acentos', 'acentuaban', 'aceptar', 'aceptar\\xc3\\xa1', 'aceptase', 'acept\\xc3\\xa1bamos', 'acept\\xc3\\xa9', 'acerado', 'acercaba', 'acercamos', 'acercando', 'acercarse', 'acerc\\xc3\\xa1ndose', 'acerc\\xc3\\xb3', 'acetosa', 'acevedo', 'aclam\\xc3\\xb3', 'acogida', 'acogido', 'acogiera', 'acompa\\xc3\\xb1a', 'acompa\\xc3\\xb1aba', 'acompa\\xc3\\xb1ada', 'acompa\\xc3\\xb1ado', 'acompa\\xc3\\xb1ados', 'acompa\\xc3\\xb1amiento', 'acompa\\xc3\\xb1antes', 'acompa\\xc3\\xb1ar', 'acompa\\xc3\\xb1arle', 'acompa\\xc3\\xb1arme', 'acompa\\xc3\\xb1ase', 'acompa\\xc3\\xb1\\xc3\\xa1banle', 'acompa\\xc3\\xb1\\xc3\\xa9', 'aconsej\\xc3\\xb3']\n"
     ]
    }
   ],
   "source": [
    "base_words = sorted(list(set(words)))\n",
    "\n",
    "print(\"Se encontraron {} palabras diferentes\".format(len(base_words)))\n",
    "print(base_words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1305"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def index(word):\n",
    "    if base_words.count(word.lower()) > 0:\n",
    "        return base_words.index(word.lower()) + 1\n",
    "    return 0\n",
    "\n",
    "index(\"casa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index(\"hola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hola', 'como', 'has', 'estado']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_words(text):\n",
    "    return [m.group(0).lower() for m in re.finditer(r\"[\\wáéíóúñ]+\", text)]\n",
    "    \n",
    "text_to_words(\"Hola como has estado?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1647, 3926, 3142]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def words_to_vec(words):\n",
    "    return [index(word) for word in words]\n",
    "\n",
    "words_to_vec(['hola', 'como', 'has', 'estado'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1647, 3926, 3142]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = 20\n",
    "def norm_vec(vec):\n",
    "    vec = vec[:MAX_LEN]\n",
    "    n = len(vec)\n",
    "    vec = [0] * (MAX_LEN - n) + vec\n",
    "    return vec\n",
    "\n",
    "norm_vec([0, 1647, 3926, 3142])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5125, 4809, 0, 8720, 7950, 5378, 7444]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_to_vec(text):\n",
    "    words = text_to_words(text)\n",
    "    vec = words_to_vec(words)\n",
    "    vec = norm_vec(vec)\n",
    "    return vec\n",
    "\n",
    "text_to_vec(\"hola me llamo Damian y tengo mucha sed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Using cached https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python2.7/site-packages (from keras) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/site-packages (from keras) (1.0.6)\n",
      "Collecting scipy>=0.14 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/d6/3eac96ffcf7cbeb37ed72982cf3fdd3138472cb04ab32cdce1f444d765f2/scipy-1.1.0-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (16.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.8MB 288kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /usr/local/lib/python2.7/site-packages (from keras) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python2.7/site-packages (from keras) (1.15.4)\n",
      "Collecting pyyaml (from keras)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/site-packages (from keras) (1.0.5)\n",
      "Installing collected packages: scipy, pyyaml, keras\n",
      "Successfully installed keras-2.2.4 pyyaml-3.13 scipy-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.sequential.Sequential object at 0x12b09ba90>\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, GRU, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "EMBEDDING_SIZE = 8\n",
    "model.add(Embedding(\n",
    "    input_dim=len(base_words) + 1,\n",
    "    output_dim=EMBEDDING_SIZE,\n",
    "    input_length=MAX_LEN\n",
    "))\n",
    "\n",
    "model.add(GRU(16, return_sequences=True))\n",
    "model.add(GRU(4))\n",
    "\n",
    "# Definimos la capa Densa para el entrenamiento\n",
    "model.add(Dense(2, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2747, 1212, 0, 899, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2747, 1212, 0, 1635, 8059, 2747, 8009], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2747, 6167, 0, 899, 8184], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5559, 6676, 2255, 2192, 3108, 1, 7773, 2658], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7960, 0, 5931, 8056, 4600, 7475], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1696, 0, 899, 7455], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8059, 2747, 2683, 2827, 6031], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2995, 0, 1647, 4885, 2295], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5559, 7960, 4126, 2192, 6374, 4861, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7773, 0, 2995, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2995, 5434, 7282, 6738, 2747, 8501], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2995, 0, 2827, 2747, 1209], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1696, 900, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5559, 6322, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2747, 1137, 5434, 4774], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7960, 8258, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7846, 5747, 2996, 7894, 5521, 1647, 4600, 5563], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3136, 7690, 2827, 2747, 5407]]\n",
      "[[1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [1, 0], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1], [0, 1]]\n"
     ]
    }
   ],
   "source": [
    "test = [\n",
    "    (\"El can lucia bastante comodo\", 1, 0),\n",
    "    (\"El can busco comida todo el tiempo\", 1, 0),\n",
    "    (\"El perro lucia bastante triste\", 1, 0),\n",
    "    (\"No pudo dejar de esperar a su dueño\", 1, 0),\n",
    "    (\"Tenía alimento para toda la semana\", 1, 0),\n",
    "    (\"Comía croquetas bastante seguido\", 1, 0),\n",
    "    (\"Jugaba todo el día en patio\", 1, 0),\n",
    "    (\"Era pulgoso como los demás\", 1, 0),\n",
    "    (\"No tenía idea de porque lo abandonaron\", 1, 0),\n",
    "    (\"Su trote era veloz\", 0, 1),\n",
    "    (\"Era más rápido que el viento\", 0, 1),\n",
    "    (\"Era libre en el campo\", 0, 1),\n",
    "    (\"Comía bastantes zanahorias\", 0, 1),\n",
    "    (\"No podía estarse quieto\", 0, 1),\n",
    "    (\"El caballo más listo\", 0, 1),\n",
    "    (\"Tenía un espirítu rebelde\", 0, 1),\n",
    "    (\"Sus ojos eran tan negros como la noche\", 0, 1),\n",
    "    (\"Estaba solo en el mundo\", 0, 1),\n",
    "]\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for text, p, c in test:\n",
    "    x_train.append(text_to_vec(text))\n",
    "    y_train.append([p, c])\n",
    "    \n",
    "print(x_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "18/18 [==============================] - 3s 174ms/step - loss: 0.2504 - acc: 0.2778\n",
      "Epoch 2/20\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2503 - acc: 0.3889\n",
      "Epoch 3/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2501 - acc: 0.3889\n",
      "Epoch 4/20\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2500 - acc: 0.4444\n",
      "Epoch 5/20\n",
      "18/18 [==============================] - 0s 2ms/step - loss: 0.2499 - acc: 0.5000\n",
      "Epoch 6/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2498 - acc: 0.7222\n",
      "Epoch 7/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2496 - acc: 0.7222\n",
      "Epoch 8/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2495 - acc: 0.7222\n",
      "Epoch 9/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2494 - acc: 0.7222\n",
      "Epoch 10/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2493 - acc: 0.8333\n",
      "Epoch 11/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2491 - acc: 0.8333\n",
      "Epoch 12/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2490 - acc: 0.8333\n",
      "Epoch 13/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2488 - acc: 0.7778\n",
      "Epoch 14/20\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 0.2487 - acc: 0.8889\n",
      "Epoch 15/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2485 - acc: 0.8889\n",
      "Epoch 16/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2484 - acc: 0.8889\n",
      "Epoch 17/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2482 - acc: 0.8333\n",
      "Epoch 18/20\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 0.2480 - acc: 0.8333\n",
      "Epoch 19/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2478 - acc: 0.8889\n",
      "Epoch 20/20\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 0.2475 - acc: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12a039e90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "model.fit(np.array(x_train), np.array(y_train), epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0 2747 1137]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.49611136, 0.5031685 ]], dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"El caballo\"\n",
    "\n",
    "vec = np.array([text_to_vec(text)])\n",
    "\n",
    "print(vec)\n",
    "\n",
    "model.predict(vec)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
