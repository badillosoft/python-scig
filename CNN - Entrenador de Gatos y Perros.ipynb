{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenador de Gatos y Perros\n",
    "Alan Badillo Salas (badillo.soft@hotmail.com)\n",
    "\n",
    "Este mini-proyecto tiene la intención de crear una red neuronal de tipo CNN, para aprender a determinar si una imagen corresponde a un gato o a un perro.\n",
    "\n",
    "Para más información sobre las redes CNN visita: https://medium.freecodecamp.org/an-intuitive-guide-to-convolutional-neural-networks-260c2de0a050"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo primero que debemos hacer es descargar el archivo zip que contiene 10,000 imágenes de gatos y perros en una resolución de 32x32 pixeles a color. Cada imagen tiene como nombre su identificador. El archivo de imágenes lo puede descargar de http://badillosoft.com/train_cat_dog.zip.\n",
    "\n",
    "Una vez descargado el archivo debemos descomprimirlo y todas las imágenes se encontrarán la carpeta `train_cat_dog`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han importado las librerías necesarias para el análisis\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Activation, Dense, Dropout, BatchNormalization\n",
    "from keras import optimizers, regularizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Se han importado las librerías necesarias para el análisis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero hay que cargar el `DataFrame` con los id's de las imágenes y sus etiquetas para utilizarlos en el proceso de aprendizaje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 3 columns):\n",
      "Unnamed: 0    10000 non-null int64\n",
      "id            10000 non-null int64\n",
      "label         10000 non-null object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 234.4+ KB\n",
      "None\n",
      "   Unnamed: 0  id label\n",
      "0           9  10   cat\n",
      "1          17  18   cat\n",
      "2          21  22   cat\n",
      "3          26  27   cat\n",
      "4          27  28   dog\n"
     ]
    }
   ],
   "source": [
    "train_cat_dog = pd.read_csv(\"http://badillosoft.com/train_cat_dog.csv\")\n",
    "\n",
    "print(train_cat_dog.info())\n",
    "print(train_cat_dog.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un generador de datos para que tome el `DataFrame` de pandas que contiene los id's de las imágenes y sus etiquetas (`train_cat_dog`). Observa que el generador de datos define que el 20% de ellos serán utilizados para la validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.preprocessing.image.ImageDataGenerator object at 0x1273c1210>\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255., validation_split=0.2)\n",
    "\n",
    "print(datagen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos el generador de entrenamiento, esto se refiere a un generador que va a cargar las imágenes desde nuestra carpeta basado en el `DataFrame` (`train_cat_dog`) para proveer el `x_train` y el `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"training\",                 # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De forma similar vamos a crear un generador de imágenes para las validaciones, esto creará los `x_test` y los `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_cat_dog,           # Dataframe de pandas con los id's de las imágnes y las etiquetas\n",
    "    directory=\"./train_cat_dog\",       # La ruta a la carpeta que contiene las imágenes de entrenamiento\n",
    "    x_col=\"id\",                        # La columna del dataframe para formar x_train, y_train\n",
    "    y_col=\"label\",                     # La columna del dataframe para formar x_test, y_test\n",
    "    has_ext=False,                     # Indica si la columna x ya tiene la extensión de la imagen\n",
    "    subset=\"validation\",               # Indica el tipo de generador (training o validation)\n",
    "    batch_size=32,                     # Indica el tamaño del bloque para las épocas\n",
    "    seed=42,                           # Indica la semilla aleatoria\n",
    "    shuffle=True,                      # Indica si las imágenes se cargarán aleatoriamente\n",
    "    class_mode=\"categorical\",          # Indica el tipo de aprendizaje (en este caso categoríco)\n",
    "    target_size=(32, 32)               # Indica la resolución de las imágenes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con los generadores anteriores, ya podemos alimentar nuestra red CNN. Por lo que, primero debemos crear la CNN como sigue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 27,586\n",
      "Trainable params: 27,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Capas Convolutivas (El filtro/kernel)\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=(32, 32, 3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "\n",
    "#model.add(Conv2D(32, (3, 3)))\n",
    "#model.add(Activation(\"relu\"))\n",
    "\n",
    "# Capas Pooling (El reductor)\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Capa Dropout (La pérdida)\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#model.add(Conv2D(64, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Capa Flatten (El aplanador)\n",
    "model.add(Flatten())\n",
    "\n",
    "# Capas de Clasificación (El aprendizaje)\n",
    "model.add(Dense(2, activation=\"softmax\"))\n",
    "\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que tenemos el modelo, podemos entrenarlo con los generadores `train_generator` y `test_generator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 21s 84ms/step - loss: 0.6715 - acc: 0.5887 - val_loss: 0.6471 - val_acc: 0.5894\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 19s 78ms/step - loss: 0.6283 - acc: 0.6531 - val_loss: 0.6055 - val_acc: 0.6687\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 21s 82ms/step - loss: 0.5998 - acc: 0.6750 - val_loss: 0.5965 - val_acc: 0.6839\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 20s 80ms/step - loss: 0.5753 - acc: 0.7041 - val_loss: 0.5599 - val_acc: 0.7195\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 24s 94ms/step - loss: 0.5601 - acc: 0.7104 - val_loss: 0.5581 - val_acc: 0.7180\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 22s 89ms/step - loss: 0.5451 - acc: 0.7220 - val_loss: 0.5561 - val_acc: 0.7221\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 27s 109ms/step - loss: 0.5340 - acc: 0.7261 - val_loss: 0.5495 - val_acc: 0.7170\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 24s 95ms/step - loss: 0.5208 - acc: 0.7374 - val_loss: 0.5375 - val_acc: 0.7266\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 21s 83ms/step - loss: 0.5139 - acc: 0.7439 - val_loss: 0.5705 - val_acc: 0.7068\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 20s 79ms/step - loss: 0.4970 - acc: 0.7549 - val_loss: 0.5391 - val_acc: 0.7276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1281ef390>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculamos los tamaños de salto para los kernels\n",
    "STEP_TRAIN = train_generator.n // train_generator.batch_size\n",
    "STEP_TEST = test_generator.n // test_generator.batch_size\n",
    "\n",
    "model.fit_generator(\n",
    "    generator=train_generator,      # Indica quién genera las imágenes de entranamiento\n",
    "    steps_per_epoch=STEP_TRAIN,     # Indica cuántos pasos se realizarán por época\n",
    "    validation_data=test_generator, # Indica el generador de imágenes para la validación\n",
    "    validation_steps=STEP_TEST,     # Indica cuántos pasos se realizarán para la validación\n",
    "    epochs=10                       # Indica las épocas de entrenamiento\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora la red CNN ya está entrenada, por lo que medimos su desempeño con las imágenes de validación (`test_generator`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.54556034880925, 0.7220528455284553]\n"
     ]
    }
   ],
   "source": [
    "metrics = model.evaluate_generator(generator=test_generator, steps=STEP_TEST)\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probar el clasificador con imágenes reales\n",
    "\n",
    "Hasta aquí ya hemos entrenado nuestro modelo para aprender a reconocer imágenes de gatos y perros, por lo que podemos ahora descargar una imagen desde internet, reducirla a una resolución de `32x32` pixeles y evaluarla en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=1000x700 at 0x127F7B190>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "# Python 2\n",
    "from StringIO import StringIO\n",
    "\n",
    "# Gato\n",
    "url = \"https://www.readersdigest.ca/wp-content/uploads/sites/14/2011/01/4-ways-cheer-up-depressed-cat.jpg\"\n",
    "# Perro\n",
    "#url = \"https://img.huffingtonpost.com/asset/5b7fdeab1900001d035028dc.jpeg?cache=sixpwrbb1s&ops=1910_1000\"\n",
    "# Gato\n",
    "#url = \"https://newsline.com/wp-content/uploads/2018/08/22698/636124053572235005-101816orange-cat-thinkstock.jpg\"\n",
    "# Perro\n",
    "#url = \"https://www.guidedogs.org/wp-content/uploads/2018/01/Mobile.jpg\"\n",
    "\n",
    "# Python 2\n",
    "response = requests.get(url)\n",
    "# Python 3\n",
    "# response = request.get(url, stream=True)\n",
    "\n",
    "# Python 2\n",
    "im = Image.open(StringIO(response.content))\n",
    "# Python 3\n",
    "# im = Image.open(response.raw)\n",
    "\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora hay que reducir la imagen a `32x32` pixeles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x127F6DDD0>\n"
     ]
    }
   ],
   "source": [
    "im = im.resize((32, 32), Image.NEAREST)\n",
    "\n",
    "print(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos convertir la imagen en un arreglo de números `(32, 32, 3)` y convertirlo a una matriz para que se pueda hacer la predicción. Recordemos que `model.predict` espera una matriz de muestras para hacer la predicción en todas las muestras (no podemos manderle sólo un ejemplo para la predicción)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[181 178 185]\n",
      "   [147 146 154]\n",
      "   [195 195 205]\n",
      "   ...\n",
      "   [100 104 113]\n",
      "   [ 89  93 102]\n",
      "   [ 86  90  99]]\n",
      "\n",
      "  [[178 173 179]\n",
      "   [141 138 145]\n",
      "   [190 190 200]\n",
      "   ...\n",
      "   [121 125 134]\n",
      "   [113 117 126]\n",
      "   [109 113 122]]\n",
      "\n",
      "  [[175 170 176]\n",
      "   [135 132 139]\n",
      "   [187 187 195]\n",
      "   ...\n",
      "   [121 125 134]\n",
      "   [115 118 125]\n",
      "   [113 116 123]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[200 197 192]\n",
      "   [205 204 199]\n",
      "   [200 197 192]\n",
      "   ...\n",
      "   [184 183 179]\n",
      "   [181 180 176]\n",
      "   [180 179 175]]\n",
      "\n",
      "  [[201 198 193]\n",
      "   [195 192 187]\n",
      "   [203 200 195]\n",
      "   ...\n",
      "   [186 185 181]\n",
      "   [186 185 181]\n",
      "   [184 183 179]]\n",
      "\n",
      "  [[205 202 197]\n",
      "   [197 194 189]\n",
      "   [207 203 200]\n",
      "   ...\n",
      "   [196 195 191]\n",
      "   [197 196 192]\n",
      "   [195 194 190]]]]\n"
     ]
    }
   ],
   "source": [
    "im_array = np.asarray(im)\n",
    "\n",
    "x_test = np.array([im_array]) # np.array([im1, im2, im3, ...])\n",
    "\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ya podemos hacer la predicción sobre `x_test`. El resultado nos va a indicar un vector con la probabilidad de que pertenezca a las distintas clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.807464e-26 1.000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(x_test)\n",
    "\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso tenemos dos clases y nos está indicando que tiene una probabilidad `0` de pertenecer a la primer clase y una probabilidad de `1` de pertenecer a la segunda clase. Para ver las clases hacemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dog': 1, 'cat': 0}\n"
     ]
    }
   ],
   "source": [
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a tomar las clases y los resultados de la predicción para que imprima que combine los scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog: 1.0\n",
      "cat: 0.0\n"
     ]
    }
   ],
   "source": [
    "class_indices = train_generator.class_indices\n",
    "for label in class_indices:\n",
    "    for score in predict:\n",
    "        index = class_indices[label]\n",
    "        print(\"{}: {}\".format(label, score[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar el modelo y entrenamiento\n",
    "\n",
    "Ahora que ya todo está listo podemos guardar el modelo y su entrenamiento para poder utilizarlo en otras aplicaciones como se verá más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"cat_dog_classes.json\", \"w\") as f:\n",
    "    f.write(json.dumps(class_indices))\n",
    "\n",
    "with open(\"cat_dog_model.json\", \"w\") as f:\n",
    "    f.write(model.to_json())\n",
    "\n",
    "model.save(\"cat_dog_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponer una interfaz web y servicios web (API-REST)\n",
    "\n",
    "Finalmente podemos generar mediante flask un servidor que reciba la url de una imagen y nos diga si es perro o si es gato. Así como proveer una página web con una caja y botón que nos diga sobre una url si es gato o si es perro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [09/Nov/2018 11:52:41] \"\u001b[37mGET /api/cat_dog?url=https%3A%2F%2Fwww.catster.com%2Fwp-content%2Fuploads%2F2017%2F10%2FA-kitten-meowing-with-his-mouth-open.jpg HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [09/Nov/2018 11:52:41] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "# Python 2\n",
    "from StringIO import StringIO\n",
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "with open(\"cat_dog_model.json\") as f:\n",
    "    model = model_from_json(f.read())\n",
    "\n",
    "model.load_weights(\"cat_dog_weights.h5\")\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "with open(\"cat_dog_classes.json\") as f:\n",
    "    class_indices = json.load(f)\n",
    "\n",
    "def cat_dog_predict(url):\n",
    "    response = requests.get(url)\n",
    "    im = Image.open(StringIO(response.content))\n",
    "    im = im.resize((32, 32), resample=Image.NEAREST)\n",
    "    im_vec = np.asarray(im)\n",
    "    x_test = np.array([im_vec])\n",
    "    predict = model.predict(x_test)[0]\n",
    "    score = {}\n",
    "    for cat in class_indices:\n",
    "        index = class_indices[cat]\n",
    "        score[cat] = predict[index]\n",
    "    return score\n",
    "\n",
    "#print(cat_dog_predict(\"https://www.guidedogs.org/wp-content/uploads/2018/01/Mobile.jpg\"))\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "html = '''\n",
    "<form action=\"/api/cat_dog\" method=\"get\">\n",
    "    <input id=\"url\" name=\"url\" placeholder=\"url de gato o perro\" >\n",
    "</form>\n",
    "'''\n",
    "\n",
    "@app.route(\"/\")\n",
    "def home():\n",
    "    return html\n",
    "\n",
    "@app.route(\"/api/cat_dog\")\n",
    "def cat_dog():\n",
    "    url = request.args[\"url\"]\n",
    "    score = cat_dog_predict(url)\n",
    "    result = '<img src=\"{}\" width=\"200\" >'.format(url)\n",
    "    for cat in score:\n",
    "        result += \"<h1>{}: {}</h1>\".format(cat, score[cat])\n",
    "    result += html\n",
    "    return result\n",
    "\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
